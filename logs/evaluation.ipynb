{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Janus (v 0.1.2)\n",
    "This notebook allows us to evaluate Janus and output relevant metrics for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 02:40:08.669527: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-21 02:40:08.716266: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 02:40:08.928535: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-21 02:40:08.929483: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 02:40:09.975075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Transforming image to standardized numpy array:\n",
    "def to_array(image_path):\n",
    "\timg_arr=cv2.imread(image_path)\n",
    "\timg_arr=cv2.resize(img_arr,(224,224))\n",
    "\ttest_input=np.array([img_arr])\n",
    "\ttest_input=test_input/225.0\n",
    "\treturn test_input\n",
    "\n",
    "# Printing the result:\n",
    "def get_result(result):\n",
    "\tif result == 0: \n",
    "\t\treturn \"ABSENT\"\n",
    "\tif result == 1: \n",
    "\t\treturn \"EVEN\"\n",
    "\tif result == 2: \n",
    "\t\treturn \"WEIGHTED\"\n",
    "\n",
    "# Reconstructing janus:\n",
    "reconstructed_janus = load_model(\"../janus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on a single image:\n",
    "image_path = input(\"Input image path: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 359ms/step\n",
      "/home/juris/local/199_ariadne/janus/final-dataset/val/absent/BradfordianPopup.png is ABSENT\n"
     ]
    }
   ],
   "source": [
    "# Checking the result:\n",
    "result = reconstructed_janus.predict(to_array(image_path)).argmax(axis=1)[0]\n",
    "print(image_path + \" is \" + get_result(result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Testing using data that was part of the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n"
     ]
    }
   ],
   "source": [
    "val_path=\"../final-dataset/val\"\n",
    "\n",
    "val_file = []\n",
    "val_arr= []\n",
    "val_ref = []\n",
    "val_pred = []\n",
    "\n",
    "for folder in os.listdir(val_path):\n",
    "    sub_path=val_path+\"/\"+folder \n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        val_file.append(image_path)\n",
    "        val_arr.append(to_array(image_path))\n",
    "        val_ref.append(folder)\n",
    "        val_pred.append(get_result(reconstructed_janus.predict(to_array(image_path)).argmax(axis=1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            File Path  \\\n",
      "0    ../final-dataset/val/weighted/CostaNewsPopup.png   \n",
      "1   ../final-dataset/val/weighted/BloombergPopup1.png   \n",
      "2          ../final-dataset/val/weighted/CBCPopup.png   \n",
      "3       ../final-dataset/val/weighted/AbantePopup.png   \n",
      "4    ../final-dataset/val/absent/BradfordianPopup.png   \n",
      "5   ../final-dataset/val/absent/BusinessReviewPopu...   \n",
      "6             ../final-dataset/val/absent/AAPopup.png   \n",
      "7   ../final-dataset/val/absent/CountryLivingPopup...   \n",
      "8     ../final-dataset/val/even/PressGazettePopup.png   \n",
      "9     ../final-dataset/val/even/HistoryTodayPopup.png   \n",
      "10  ../final-dataset/val/even/TheIsleOfThanetNewsP...   \n",
      "11  ../final-dataset/val/even/AlgarveDailyNewsPopu...   \n",
      "\n",
      "                                                Array     Label Prediction  \n",
      "0   [[[[0.79555556 0.79555556 0.79555556], [0.7822...  weighted   WEIGHTED  \n",
      "1   [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...  weighted   WEIGHTED  \n",
      "2   [[[[1.13333333 0.47555556 0.15555556], [1.1333...  weighted   WEIGHTED  \n",
      "3   [[[[1.08888889 1.08888889 1.08888889], [1.0888...  weighted   WEIGHTED  \n",
      "4   [[[[1.13333333 1.13333333 1.13333333], [1.1333...    absent     ABSENT  \n",
      "5   [[[[0.96444444 1.01333333 1.03111111], [0.9688...    absent     ABSENT  \n",
      "6   [[[[0.55111111 0.30222222 0.        ], [0.5511...    absent   WEIGHTED  \n",
      "7   [[[[0.48       0.43111111 0.40444444], [0.64  ...    absent     ABSENT  \n",
      "8   [[[[0.20444444 0.20444444 0.20444444], [0.2044...      even       EVEN  \n",
      "9   [[[[0.84888889 0.53777778 0.03111111], [0.8488...      even       EVEN  \n",
      "10  [[[[1.11111111 1.10666667 1.10666667], [1.1111...      even       EVEN  \n",
      "11  [[[[0.62222222 0.62222222 0.62222222], [0.6222...      even       EVEN  \n"
     ]
    }
   ],
   "source": [
    "data = {'File Path': val_file,\n",
    "        'Array': val_arr,\n",
    "\t\t'Label': val_ref,\n",
    "\t\t'Prediction': val_pred}\n",
    "\n",
    "df_val = pd.DataFrame(data)\n",
    "print(df_val)\n",
    "df_val.to_csv('validation.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Testing using data not from the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n"
     ]
    }
   ],
   "source": [
    "test_path=\"test\"\n",
    "\n",
    "test_file = []\n",
    "test_arr= []\n",
    "test_ref = []\n",
    "test_pred = []\n",
    "\n",
    "for folder in os.listdir(test_path):\n",
    "    sub_path=test_path+\"/\"+folder \n",
    "\n",
    "    for img in os.listdir(sub_path):\n",
    "        image_path=sub_path+\"/\"+img\n",
    "        test_file.append(image_path)\n",
    "        test_arr.append(to_array(image_path))\n",
    "        test_ref.append(folder)\n",
    "        test_pred.append(get_result(reconstructed_janus.predict(to_array(image_path)).argmax(axis=1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                File Path  \\\n",
      "0              test/weighted/WSJPopup.png   \n",
      "1  test/weighted/WashingtonTimesPopup.png   \n",
      "2                 test/weighted/pepph.png   \n",
      "3            test/absent/WeForumPopup.png   \n",
      "4    test/absent/WorkinghamPaperPopup.png   \n",
      "5                 test/absent/newstv5.png   \n",
      "6      test/even/WashingtonPostPopup2.png   \n",
      "7                test/even/ZDNetPopup.png   \n",
      "8                test/even/gmanetwork.png   \n",
      "\n",
      "                                               Array     Label Prediction  \n",
      "0  [[[[1.05777778 1.05777778 1.05777778], [1.0577...  weighted       EVEN  \n",
      "1  [[[[0.87111111 0.43111111 0.        ], [0.88  ...  weighted   WEIGHTED  \n",
      "2  [[[[0.11111111 0.11111111 0.11111111], [0.1111...  weighted   WEIGHTED  \n",
      "3  [[[[1.11111111 1.10666667 1.10666667], [1.1111...    absent   WEIGHTED  \n",
      "4  [[[[0.22222222 0.20888889 0.21333333], [0.3111...    absent     ABSENT  \n",
      "5  [[[[0.28444444 0.33777778 0.85777778], [0.2844...    absent       EVEN  \n",
      "6  [[[[0.62666667 0.50666667 0.37333333], [0.6355...      even       EVEN  \n",
      "7  [[[[0. 0. 0.], [0. 0. 0.], [0. 0. 0.], [0. 0. ...      even       EVEN  \n",
      "8  [[[[0.27555556 0.27111111 0.28444444], [0.2755...      even   WEIGHTED  \n"
     ]
    }
   ],
   "source": [
    "data = {'File Path': test_file,\n",
    "        'Array': test_arr,\n",
    "\t\t'Label': test_ref,\n",
    "\t\t'Prediction': test_pred}\n",
    "\n",
    "df_test = pd.DataFrame(data)\n",
    "print(df_test)\n",
    "df_test.to_csv('testing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
